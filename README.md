# GPT FROM SCRATCH
This is a GPT exercise made from scratch
it's based on a class given by Andrej Karpathy (OPENAI)
The architecture used is based on the original paper 'Attention is all you need'
8 multihead attention implemented.
character embedding were used instead of word embedding
all Shakespeare text was ingested for generating similar text
The model were trained during 2,000 iterations
reaching a loss aroung 1.6 for validating set.

any suggestion don't hesitate on contacting me vizcayaluis1@gmail.com
